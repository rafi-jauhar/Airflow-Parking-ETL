[2022-12-28 20:11:42,544] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: parking_pipeline.create_table scheduled__2022-12-28T20:09:19.129161+00:00 [queued]>
[2022-12-28 20:11:42,552] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: parking_pipeline.create_table scheduled__2022-12-28T20:09:19.129161+00:00 [queued]>
[2022-12-28 20:11:42,553] {taskinstance.py:1356} INFO - 
--------------------------------------------------------------------------------
[2022-12-28 20:11:42,554] {taskinstance.py:1357} INFO - Starting attempt 1 of 2
[2022-12-28 20:11:42,555] {taskinstance.py:1358} INFO - 
--------------------------------------------------------------------------------
[2022-12-28 20:11:42,564] {taskinstance.py:1377} INFO - Executing <Task(PostgresOperator): create_table> on 2022-12-28 20:09:19.129161+00:00
[2022-12-28 20:11:42,568] {standard_task_runner.py:52} INFO - Started process 457 to run task
[2022-12-28 20:11:42,573] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'parking_pipeline', 'create_table', 'scheduled__2022-12-28T20:09:19.129161+00:00', '--job-id', '7', '--raw', '--subdir', 'DAGS_FOLDER/parking_dag.py', '--cfg-path', '/tmp/tmpeh6vblu2', '--error-file', '/tmp/tmpw93twes2']
[2022-12-28 20:11:42,574] {standard_task_runner.py:80} INFO - Job 7: Subtask create_table
[2022-12-28 20:11:42,631] {task_command.py:369} INFO - Running <TaskInstance: parking_pipeline.create_table scheduled__2022-12-28T20:09:19.129161+00:00 [running]> on host 8be693a2d03b
[2022-12-28 20:11:42,694] {taskinstance.py:1571} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=Airflow
AIRFLOW_CTX_DAG_ID=parking_pipeline
AIRFLOW_CTX_TASK_ID=create_table
AIRFLOW_CTX_EXECUTION_DATE=2022-12-28T20:09:19.129161+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-12-28T20:09:19.129161+00:00
[2022-12-28 20:11:42,705] {base.py:68} INFO - Using connection ID 'postgres' for task execution.
[2022-12-28 20:11:42,714] {dbapi.py:208} INFO - Running statement: 
            drop table if exists parking_data;
            create table parking_data(
                startDtm text not null,
                endDtm text not null,
                transactionAmt float not null,
                paymentTypeName text not null,
                transactionStatusCode text not null,
                maxHoursCnt text not null,
                meterTypeDsc text not null,
                dollarPerHourRate text not null,
                activeStatusInd bool not null,
                metroAreaName text not null
            );
        , parameters: None
[2022-12-28 20:11:42,723] {taskinstance.py:1889} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/postgres/operators/postgres.py", line 92, in execute
    self.hook.run(self.sql, self.autocommit, parameters=self.parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/hooks/dbapi.py", line 188, in run
    self._run_command(cur, sql_statement, parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/hooks/dbapi.py", line 212, in _run_command
    cur.execute(sql_statement)
psycopg2.errors.UniqueViolation: duplicate key value violates unique constraint "pg_type_typname_nsp_index"
DETAIL:  Key (typname, typnamespace)=(parking_data, 2200) already exists.

[2022-12-28 20:11:42,733] {taskinstance.py:1400} INFO - Marking task as UP_FOR_RETRY. dag_id=parking_pipeline, task_id=create_table, execution_date=20221228T200919, start_date=20221228T201142, end_date=20221228T201142
[2022-12-28 20:11:42,741] {standard_task_runner.py:97} ERROR - Failed to execute job 7 for task create_table (duplicate key value violates unique constraint "pg_type_typname_nsp_index"
DETAIL:  Key (typname, typnamespace)=(parking_data, 2200) already exists.
; 457)
[2022-12-28 20:11:42,787] {local_task_job.py:156} INFO - Task exited with return code 1
[2022-12-28 20:11:42,823] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
